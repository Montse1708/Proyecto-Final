




















# Importamos módulos para la carga,manejo, grafica de datos
import pyspark.sql.functions as f 
import pyspark.sql.types as t
import matplotlib.pyplot as plt



# Creamos sesión de Spark
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("IT_Salary") \
    .getOrCreate()


# Cargamos los datos de 2018
datasets_path = 'data/'
dataset2018_path=f'{datasets_path}/IT Salary Survey EU 2018.csv'
salaries2018 = spark.read.format('csv').option('header', True).load(dataset2018_path)


#Renombramos columnas para un mejor manejo de los datos
salaries2018 = salaries2018.withColumnRenamed('Total years of experience', 'YearsExperience'
).withColumnRenamed('Years of experience in Germany', 'YersExpGermany'  
).withColumnRenamed('Seniority Level', 'SeniorityLevel' 
).withColumnRenamed('Your main technology / programming language' , 'ProgrammingLanguage'
).withColumnRenamed('Other technologies/programming languages you use often', 'OtherTech'
).withColumnRenamed('Yearly brutto salary (without bonus and stocks) in EUR', 'YearSalary'
).withColumnRenamed('Yearly bonus + stocks in EUR', 'YearBonus'
).withColumnRenamed('Annual brutto salary (without bonus and stocks) one year ago. Only answer if staying in the same country', 'PrevYearSalary'
).withColumnRenamed('Annual bonus+stocks one year ago. Only answer if staying in same country','PrevYearBonus'                   
).withColumnRenamed('Number of vacation days', 'VacationsDays'
).withColumnRenamed('Employment status', 'EmployStatus'
).withColumnRenamed('Сontract duration', 'СontractDuration' 
).withColumnRenamed('Main language at work', 'MainLanguage' 
).withColumnRenamed('Company size', 'CompanySize' 
).withColumnRenamed('Have you lost your job due to the coronavirus outbreak?', 'LostJobCoronavirus'
).withColumnRenamed('Have you been forced to have a shorter working week (Kurzarbeit)? If yes, how many hours per week', 'ShorterWorkingWeek'  
).withColumnRenamed('Have you received additional monetary support from your employer due to Work From Home? If yes, how much in 2020 in EUR', 'PayWorkHome'                    
)


salaries2018.show(truncate=False, vertical=True)


# Cargamos los datos de 2019
dataset2019_path=f'{datasets_path}/IT Salary Survey EU 2019.csv'
salaries2019 = spark.read.format('csv').option('header', True).load(dataset2019_path)


#Renombramos columnas para un mejor manejo de los datos
salaries2019 = salaries2019.withColumnRenamed('Total years of experience', 'YearsExperience'
).withColumnRenamed('Years of experience in Germany', 'YersExpGermany'  
).withColumnRenamed('Seniority Level', 'SeniorityLevel' 
).withColumnRenamed('Your main technology / programming language' , 'ProgrammingLanguage'
).withColumnRenamed('Other technologies/programming languages you use often', 'OtherTech'
).withColumnRenamed('Yearly brutto salary (without bonus and stocks) in EUR', 'YearSalary'
).withColumnRenamed('Yearly bonus + stocks in EUR', 'YearBonus'
).withColumnRenamed('Annual brutto salary (without bonus and stocks) one year ago. Only answer if staying in the same country', 'PrevYearSalary'
).withColumnRenamed('Annual bonus+stocks one year ago. Only answer if staying in same country','PrevYearBonus'                   
).withColumnRenamed('Number of vacation days', 'VacationsDays'
).withColumnRenamed('Employment status', 'EmployStatus'
).withColumnRenamed('Сontract duration', 'СontractDuration' 
).withColumnRenamed('Main language at work', 'MainLanguage' 
).withColumnRenamed('Company size', 'CompanySize' 
).withColumnRenamed('Have you lost your job due to the coronavirus outbreak?', 'LostJobCoronavirus'
).withColumnRenamed('Have you been forced to have a shorter working week (Kurzarbeit)? If yes, how many hours per week', 'ShorterWorkingWeek'  
).withColumnRenamed('Have you received additional monetary support from your employer due to Work From Home? If yes, how much in 2020 in EUR', 'PayWorkHome'                    
)


#Mostramos los datos 2019
salaries2019.show(truncate=False, vertical = True)


# Cargamos los datos de 2020
datasets_path = 'data/'
dataset2020_path=f'{datasets_path}/IT Salary Survey EU 2020.csv'
salaries2020 = spark.read.format('csv').option('header', True).load(dataset2020_path)


#Renombramos columnas para un mejor manejo de los datos
salaries2020 = salaries2020.withColumnRenamed('Total years of experience', 'YearsExperience'
).withColumnRenamed('Years of experience in Germany', 'YersExpGermany'  
).withColumnRenamed('Seniority Level', 'SeniorityLevel' 
).withColumnRenamed('Your main technology / programming language' , 'ProgrammingLanguage'
).withColumnRenamed('Other technologies/programming languages you use often', 'OtherTech'
).withColumnRenamed('Yearly brutto salary (without bonus and stocks) in EUR', 'YearSalary'
).withColumnRenamed('Yearly bonus + stocks in EUR', 'YearBonus'
).withColumnRenamed('Annual brutto salary (without bonus and stocks) one year ago. Only answer if staying in the same country', 'PrevYearSalary'
).withColumnRenamed('Annual bonus+stocks one year ago. Only answer if staying in same country','PrevYearBonus'                   
).withColumnRenamed('Number of vacation days', 'VacationsDays'
).withColumnRenamed('Employment status', 'EmployStatus'
).withColumnRenamed('Сontract duration', 'СontractDuration' 
).withColumnRenamed('Main language at work', 'MainLanguage' 
).withColumnRenamed('Company size', 'CompanySize' 
).withColumnRenamed('Have you lost your job due to the coronavirus outbreak?', 'LostJobCoronavirus'
).withColumnRenamed('Have you been forced to have a shorter working week (Kurzarbeit)? If yes, how many hours per week', 'ShorterWorkingWeek'  
).withColumnRenamed('Have you received additional monetary support from your employer due to Work From Home? If yes, how much in 2020 in EUR', 'PayWorkHome'                    
)


#Mostramos los datos 2020
salaries2020.show(truncate=False, vertical = True)











### Verificamos estructura de los salarios
salaries2020.printSchema()


# Usaremos la columna de ProgrammingLanguage
#Eliminamos aquellos registros vacios en las columnas de interes
from pyspark.sql.functions import col

# Eliminar los registros con valores nulos en las columnas de interés
salaries2020_clean = salaries2020.filter(
    col('ProgrammingLanguage').isNotNull() 
)

# Mostrar los primeros registros para verificar
salaries2020_clean.show(truncate=True, vertical=True)


#Obtenemos los datos de lenguajes contamos la frecuencia y los ordenamos en orden descendiente
#Primero formateamos los datos minusculas para evitar repetir mismos lenguajes
language_users = salaries2020_clean.withColumn(
    "ProgrammingLanguage", 
    f.lower(f.regexp_replace(f.trim(col("ProgrammingLanguage")), r'[^\w]', ''))
)
language_users = language_users.groupBy("ProgrammingLanguage").agg(f.count("ProgrammingLanguage").alias("Users"))
language_users= language_users.orderBy(col("Users").desc())


#Graficamos los datos
language_users_df= language_users.toPandas()

plt.figure(figsize=(12, 8))
plt.bar(language_users_df["ProgrammingLanguage"][:10], language_users_df["Users"][:10], color='skyblue')
plt.xlabel("Lenguaje de Programacion")
plt.ylabel("Usuarios")
plt.title("Top 10 de Lenguajes de Programación Mas Utilizados")
plt.xticks(rotation=45)
plt.show()








### Verificamos estructura de los salarios
salaries2020.printSchema()


#Verificamos numero de filas en el archivo
salaries2020.count()


# Usaremos las columnas de Gender para filtrar entre hombres y mujeres, YearSalary como medicion del salario y Seniority level para filtrar por experiencia
#Eliminamos aquellos registros vacios en las columnas de interes
# Eliminar los registros con valores nulos en las columnas de interés
salaries2020_clean = salaries2020.filter(
    col('Gender').isNotNull() &
    col('YearSalary').isNotNull() &
    col('SeniorityLevel').isNotNull()
)

# Mostrar los primeros registros para verificar
salaries2020_clean.show(truncate=True, vertical=True)


#Verificamos numero de filas en el dataframe despues de limpieza
salaries2020_clean.count()


#Exploramos los diferentes valores de Seniority level
salaries2020_clean.dropDuplicates(['SeniorityLevel']).select('SeniorityLevel').show(truncate=False, vertical = True)


#Filtramos solo los registros en nivel senior usando SQL
# Registrar el DataFrame como una vista temporal
salaries2020_clean.createOrReplaceTempView("salaries2020_clean")
salaries2020_senior = spark.sql("""
    SELECT * FROM salaries2020_clean WHERE SeniorityLevel = 'Senior'
""")
salaries2020_senior.count()


salaries2020_senior.printSchema()


#Analizamos los datos
salaries2020_senior = salaries2020_senior.withColumn("YearSalary", col("YearSalary").cast("double"))
stats_salaries = salaries2020_senior.select(
    f.count("YearSalary").alias("count"),
    f.mean("YearSalary").alias("mean"),
    f.stddev("YearSalary").alias("stddev"),
    f.min("YearSalary").alias("min"),
    f.max("YearSalary").alias("max")
)
stats_salaries.show()





#Mostramos los datos en un histograma
from pyspark_dist_explore import hist

fig, ax = plt.subplots()
hist(ax, salaries2020_senior.select('YearSalary'), bins=16, color=['red'])
plt.title("Histograma de Salarios Anuales en Nivel Senior")
plt.xlabel("Salario Anual (EUR)")
plt.ylabel("Frecuencia")
plt.grid(axis='y', alpha=0.75)


#Ya que hay algunos outliers, procederemos a filtrar los datos usando como regla los cuartiles, para descartar todos los datos menores de Q1 y mayores a Q3
quartiles = salaries2020_senior.approxQuantile("YearSalary", [0.25, 0.75], 0.01)
q1 = quartiles[0]
q3 = quartiles[1]
iqr = q3 - q1
salaries2020_senior_clean = salaries2020_senior.filter((col("YearSalary") >= (q1 - 1.5 * iqr)) & (col("YearSalary") <= (q3 + 1.5 * iqr)))
salaries2020_senior_clean.count()


#Mostramos los datos en un histograma
from pyspark_dist_explore import hist
import matplotlib.pyplot as plt

fig, ax = plt.subplots()
hist(ax, salaries2020_senior_clean.select('YearSalary'), bins=16, color=['green'])
plt.title("Histograma de Salarios Anuales en Nivel Senior (Limpios)")
plt.xlabel("Salario Anual (EUR)")
plt.ylabel("Frecuencia")
plt.grid(axis='y', alpha=0.75)


#Procedemos a comparar los estadisticas entre hombres y mujeres
#Primero sacamos el analisis descriptivo entre generos
stats_gender = salaries2020_senior_clean.groupBy("Gender").agg(
    f.count("YearSalary").alias("count"),
    f.mean("YearSalary").alias("mean"),
    f.stddev("YearSalary").alias("stddev"),
    f.min("YearSalary").alias("min"),
    f.max("YearSalary").alias("max")
)
stats_gender.show()


#Graficamos los datos
import pandas as pd
gender_data = stats_gender.select("Gender", "mean", "stddev").collect()


df = pd.DataFrame(gender_data, columns=["Gender", "mean", "stddev"])

# Plotting
plt.bar(df['Gender'], df['mean'], yerr=df['stddev'], capsize=5)
plt.xlabel("Género")
plt.ylabel("Salario Anual Promedio (EUR)")
plt.title("Comparación de Salarios Anuales Promedio entre Hombres y Mujeres")
plt.show()


#Graficamos en histogramas separados
male_salaries = salaries2020_senior_clean.filter(col("Gender") == "Male").select("YearSalary").toPandas()
female_salaries = salaries2020_senior_clean.filter(col("Gender") == "Female").select("YearSalary").toPandas()

plt.figure(figsize=(10, 6))

plt.hist(male_salaries["YearSalary"], bins=16, alpha=0.5, label="Hombres", color='blue', edgecolor='black')
plt.hist(female_salaries["YearSalary"], bins=16, alpha=0.5, label="Female", color='red', edgecolor='black')

plt.title("Histograma del Salario Anual por Genero")
plt.xlabel("Salario Anual (EUR)")
plt.ylabel("Frecuencia")

plt.legend()

plt.show()








#Reusamos la varible salaries2020_clean
salaries2020_clean.show(truncate=True, vertical=True)


salaries2020_clean = salaries2020_clean.withColumn("YearSalary", col("YearSalary").cast("double"))

level_stats = salaries2020_clean.groupBy("SeniorityLevel").agg(
    f.count("YearSalary").alias("count"),
    f.mean("YearSalary").alias("mean"),
    f.stddev("YearSalary").alias("stddev"),
    f.min("YearSalary").alias("min"),
    f.max("YearSalary").alias("max")
)


level_stats_clean = level_stats.filter(
    col('count').isNotNull() &
    col('mean').isNotNull() &
    col('stddev').isNotNull() &
    col('min').isNotNull() &
    col('max').isNotNull() &
    (col('SeniorityLevel') != 'Middle')
)
level_stats_clean.show()



level_data = level_stats_clean.select("SeniorityLevel", "mean", "stddev").toPandas()

# Plotting
plt.bar(level_data['SeniorityLevel'], level_data['mean'], yerr=level_data['stddev'], capsize=5)
plt.xlabel("Nivel de antigüedad")
plt.ylabel("Salario Anual Promedio (EUR)")
plt.title("Comparación de Salarios Anuales Promedio entre diferentes niveles de antigüedad")
plt.show()







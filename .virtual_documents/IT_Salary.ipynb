























# Importamos módulos para la carga y manejo de datos
import pyspark.sql.functions as f 
import pyspark.sql.types as t


# Creamos sesión de Spark
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("IT_Salary") \
    .getOrCreate()


# Cargamos los datos de 2018
datasets_path = 'data/'
dataset2018_path=f'{datasets_path}/IT Salary Survey EU 2018.csv'
salaries2018 = spark.read.format('csv').option('header', True).load(datasets_path)


#Renombramos columnas para un mejor manejo de los datos
salaries2018 = salaries2018.withColumnRenamed('Total years of experience', 'YearsExperience'
).withColumnRenamed('Years of experience in Germany', 'YersExpGermany'  
).withColumnRenamed('Seniority Level', 'SeniorityLevel' 
).withColumnRenamed('Your main technology / programming language' , 'ProgrammingLanguage'
).withColumnRenamed('Other technologies/programming languages you use often', 'OtherTech'
).withColumnRenamed('Yearly brutto salary (without bonus and stocks) in EUR', 'YearSalary'
).withColumnRenamed('Yearly bonus + stocks in EUR', 'YearBonus'
).withColumnRenamed('Annual brutto salary (without bonus and stocks) one year ago. Only answer if staying in the same country', 'PrevYearSalary'
).withColumnRenamed('Annual bonus+stocks one year ago. Only answer if staying in same country','PrevYearBonus'                   
).withColumnRenamed('Number of vacation days', 'VacationsDays'
).withColumnRenamed('Employment status', 'EmployStatus'
).withColumnRenamed('Сontract duration', 'СontractDuration' 
).withColumnRenamed('Main language at work', 'MainLanguage' 
).withColumnRenamed('Company size', 'CompanySize' 
).withColumnRenamed('Have you lost your job due to the coronavirus outbreak?', 'LostJobCoronavirus'
).withColumnRenamed('Have you been forced to have a shorter working week (Kurzarbeit)? If yes, how many hours per week', 'ShorterWorkingWeek'  
).withColumnRenamed('Have you received additional monetary support from your employer due to Work From Home? If yes, how much in 2020 in EUR', 'PayWorkHome'                    
)


salaries2018.show(truncate=False, vertical = True)


# Cargamos los datos de 2019
dataset2019_path=f'{datasets_path}/IT Salary Survey EU  2019.csv'
salaries2019 = spark.read.format('csv').option('header', True).load(datasets_path)


#Renombramos columnas para un mejor manejo de los datos
salaries2019 = salaries2019.withColumnRenamed('Total years of experience', 'YearsExperience'
).withColumnRenamed('Years of experience in Germany', 'YersExpGermany'  
).withColumnRenamed('Seniority Level', 'SeniorityLevel' 
).withColumnRenamed('Your main technology / programming language' , 'ProgrammingLanguage'
).withColumnRenamed('Other technologies/programming languages you use often', 'OtherTech'
).withColumnRenamed('Yearly brutto salary (without bonus and stocks) in EUR', 'YearSalary'
).withColumnRenamed('Yearly bonus + stocks in EUR', 'YearBonus'
).withColumnRenamed('Annual brutto salary (without bonus and stocks) one year ago. Only answer if staying in the same country', 'PrevYearSalary'
).withColumnRenamed('Annual bonus+stocks one year ago. Only answer if staying in same country','PrevYearBonus'                   
).withColumnRenamed('Number of vacation days', 'VacationsDays'
).withColumnRenamed('Employment status', 'EmployStatus'
).withColumnRenamed('Сontract duration', 'СontractDuration' 
).withColumnRenamed('Main language at work', 'MainLanguage' 
).withColumnRenamed('Company size', 'CompanySize' 
).withColumnRenamed('Have you lost your job due to the coronavirus outbreak?', 'LostJobCoronavirus'
).withColumnRenamed('Have you been forced to have a shorter working week (Kurzarbeit)? If yes, how many hours per week', 'ShorterWorkingWeek'  
).withColumnRenamed('Have you received additional monetary support from your employer due to Work From Home? If yes, how much in 2020 in EUR', 'PayWorkHome'                    
)


#Mostramos los datos 2019
salaries2019.show(truncate=False, vertical = True)


# Cargamos los datos de 2020
datasets_path = 'data/'
dataset2020_path=f'{datasets_path}/IT Salary Survey EU  2020.csv'
salaries2020 = spark.read.format('csv').option('header', True).load(datasets_path)


#Renombramos columnas para un mejor manejo de los datos
salaries2020 = salaries2018.withColumnRenamed('Total years of experience', 'YearsExperience'
).withColumnRenamed('Years of experience in Germany', 'YersExpGermany'  
).withColumnRenamed('Seniority Level', 'SeniorityLevel' 
).withColumnRenamed('Your main technology / programming language' , 'ProgrammingLanguage'
).withColumnRenamed('Other technologies/programming languages you use often', 'OtherTech'
).withColumnRenamed('Yearly brutto salary (without bonus and stocks) in EUR', 'YearSalary'
).withColumnRenamed('Yearly bonus + stocks in EUR', 'YearBonus'
).withColumnRenamed('Annual brutto salary (without bonus and stocks) one year ago. Only answer if staying in the same country', 'PrevYearSalary'
).withColumnRenamed('Annual bonus+stocks one year ago. Only answer if staying in same country','PrevYearBonus'                   
).withColumnRenamed('Number of vacation days', 'VacationsDays'
).withColumnRenamed('Employment status', 'EmployStatus'
).withColumnRenamed('Сontract duration', 'СontractDuration' 
).withColumnRenamed('Main language at work', 'MainLanguage' 
).withColumnRenamed('Company size', 'CompanySize' 
).withColumnRenamed('Have you lost your job due to the coronavirus outbreak?', 'LostJobCoronavirus'
).withColumnRenamed('Have you been forced to have a shorter working week (Kurzarbeit)? If yes, how many hours per week', 'ShorterWorkingWeek'  
).withColumnRenamed('Have you received additional monetary support from your employer due to Work From Home? If yes, how much in 2020 in EUR', 'PayWorkHome'                    
)


#Mostramos los datos 2020
salaries2020.show(truncate=False, vertical = True)














### Verificamos estructura de los salarios
salaries2020.printSchema()


#Verificamos numero de filas en el archivo
salaries2020.count()


# Usaremos las columnas de Gender para filtrar entre hombres y mujeres, YearSalary como medicion del salario y Seniority level para filtrar por experiencia
#Eliminamos aquellos registros vacios en las columnas de interes
from pyspark.sql.functions import col

# Eliminar los registros con valores nulos en las columnas de interés
salaries2020_clean = salaries2020.filter(
    col('Gender').isNotNull() &
    col('YearSalary').isNotNull() &
    col('SeniorityLevel').isNotNull()
)

# Mostrar los primeros registros para verificar
salaries2020_clean.show(truncate=True, vertical=True)


#Verificamos numero de filas en el dataframe despues de limpieza
salaries2020_clean.count()


#Exploramos los diferentes valores de Seniority level
salaries2020_clean.dropDuplicates(['SeniorityLevel']).select('SeniorityLevel').show(truncate=False, vertical = True)


#Filtramos solo los registros en nivel senior usando SQL
salaries2020_senior = spark.sql("""
    SELECT * FROM salaries2020_clean WHERE SeniorityLevel = 'Senior'
""")
salaries2020_senior.show(truncate=False, vertical = True)






